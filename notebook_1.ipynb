{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKiW/WuxpoSBQZg30846sx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kotianbipin/ds_Bipin_Kotian/blob/main/notebook_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Web3 Trading Team Assignment - notebook_1.ipynb\n",
        "Candidate: bipin kotian"
      ],
      "metadata": {
        "id": "MJ_tMqq52qdC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ebuyI1tO2gom"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(\"csv_files\", exist_ok=True)\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install --quiet gdown matplotlib seaborn scikit-learn fpdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY3AjMMG21Dk",
        "outputId": "045c0e58-62e1-4e58-e3a8-fe7805c86ef4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "sentiment_file_id = \"1PgQC0tO8XN-wqkNyghWc_-mnrYv_nhSf\"\n",
        "trades_file_id    = \"1IAfLZwu6rJzyWKgBToqwSmmVYU6VbjVs\"\n",
        "\n",
        "gdown.download(f\"https://drive.google.com/uc?id={sentiment_file_id}\", \"sentiment.csv\", quiet=False)\n",
        "gdown.download(f\"https://drive.google.com/uc?id={trades_file_id}\", \"trades.csv\", quiet=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "uQVR1ZV927fH",
        "outputId": "f0fbcef3-ea8b-42df-c2de-8d63444df40f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PgQC0tO8XN-wqkNyghWc_-mnrYv_nhSf\n",
            "To: /content/sentiment.csv\n",
            "100%|██████████| 90.8k/90.8k [00:00<00:00, 43.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IAfLZwu6rJzyWKgBToqwSmmVYU6VbjVs\n",
            "To: /content/trades.csv\n",
            "100%|██████████| 47.5M/47.5M [00:00<00:00, 225MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'trades.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "trades = pd.read_csv(\"trades.csv\")\n",
        "sent = pd.read_csv(\"sentiment.csv\")\n",
        "\n",
        "print(\"Trades columns:\", trades.columns.tolist())\n",
        "print(\"Sentiment columns:\", sent.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8YnxFc53Da_",
        "outputId": "390d04ba-525e-4def-bf3e-e0f926c5be27"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trades columns: ['Account', 'Coin', 'Execution Price', 'Size Tokens', 'Size USD', 'Side', 'Timestamp IST', 'Start Position', 'Direction', 'Closed PnL', 'Transaction Hash', 'Order ID', 'Crossed', 'Fee', 'Trade ID', 'Timestamp']\n",
            "Sentiment columns: ['timestamp', 'value', 'classification', 'date']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "#  Preprocessing: trades datetime\n",
        "# -------------------------------\n",
        "time_cols = [c for c in trades.columns if 'time' in c.lower() or 'date' in c.lower()]\n",
        "if not time_cols:\n",
        "    raise ValueError(\"No time/date column found in trades dataset\")\n",
        "time_col = time_cols[0]\n",
        "trades['date'] = pd.to_datetime(trades[time_col], errors='coerce').dt.date\n"
      ],
      "metadata": {
        "id": "Hq794jzo3KhU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Preprocessing: sentiment dataset\n",
        "# -------------------------------\n",
        "sent.columns = [c.strip() for c in sent.columns]\n",
        "\n",
        "# Detect date column\n",
        "date_cols = [c for c in sent.columns if 'date' in c.lower()]\n",
        "if not date_cols:\n",
        "    raise ValueError(\"No date column found in sentiment dataset\")\n",
        "date_col = date_cols[0]\n",
        "sent['date'] = pd.to_datetime(sent[date_col], errors='coerce').dt.date\n",
        "\n",
        "# Detect sentiment/classification column\n",
        "class_cols = [c for c in sent.columns if 'class' in c.lower() or 'fear' in c.lower() or 'greed' in c.lower()]\n",
        "if not class_cols:\n",
        "    raise ValueError(\"No Classification column found in sentiment dataset\")\n",
        "class_col = class_cols[0]\n",
        "sent['Classification'] = sent[class_col].astype(str)\n",
        "\n",
        "print(sent[['date','Classification']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02XX3rOk3OFz",
        "outputId": "2628e7a6-662c-42b5-ce72-73aa46f45ccd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         date Classification\n",
            "0  2018-02-01           Fear\n",
            "1  2018-02-02   Extreme Fear\n",
            "2  2018-02-03           Fear\n",
            "3  2018-02-04   Extreme Fear\n",
            "4  2018-02-05   Extreme Fear\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Aggregate daily trader metrics\n",
        "# -------------------------------\n",
        "agg = trades.groupby('date').agg(\n",
        "    num_trades=('Account','count'),\n",
        "    total_volume=('Size USD', lambda x: abs(x).sum() if pd.api.types.is_numeric_dtype(x) else np.nan),\n",
        "    total_closed_pnl=('Closed PnL','sum'),\n",
        "    avg_closed_pnl=('Closed PnL','mean'),\n",
        "    win_rate=('Closed PnL', lambda x: (x>0).mean()),\n",
        "    avg_trade_size=('Size USD','mean')\n",
        ").reset_index()\n",
        "\n",
        "# Merge with sentiment\n",
        "daily = agg.merge(sent[['date','Classification']], on='date', how='left').sort_values('date')\n",
        "daily['sent_code'] = daily['Classification'].map({'Fear':0,'Greed':1})\n"
      ],
      "metadata": {
        "id": "dZB3V-V_3TPr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daily.to_csv(\"csv_files/daily_features.csv\", index=False)"
      ],
      "metadata": {
        "id": "YV0AEkHX3d9Q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Exploratory Data Analysis (EDA)\n",
        "# -------------------------------\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Daily total PnL by sentiment\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.lineplot(data=daily, x='date', y='total_closed_pnl', hue='Classification')\n",
        "plt.title(\"Daily Total PnL vs Market Sentiment\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"outputs/daily_pnl.png\")\n",
        "plt.close()\n",
        "\n",
        "# Avg trade size vs Avg closed PnL\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.scatterplot(x='avg_trade_size', y='avg_closed_pnl', hue='Classification', data=daily)\n",
        "plt.title(\"Avg Trade Size vs Avg Closed PnL by Sentiment\")\n",
        "plt.savefig(\"outputs/scatter_trade_pnl.png\")\n",
        "plt.close()\n",
        "\n",
        "# Avg leverage vs sentiment (if exists)\n",
        "if 'leverage' in trades.columns:\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.boxplot(x='Classification', y='avg_leverage', data=daily)\n",
        "    plt.title(\"Average Leverage by Sentiment\")\n",
        "    plt.savefig(\"outputs/boxplot_leverage.png\")\n",
        "    plt.close()\n",
        "\n",
        "# Number of trades per day\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.lineplot(data=daily, x='date', y='num_trades', hue='Classification')\n",
        "plt.title(\"Number of Trades per Day vs Market Sentiment\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"outputs/daily_trades.png\")\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "17wpYxZF3jCV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Statistical test: Fear vs Greed PnL\n",
        "# -------------------------------\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "fear_pnl = daily[daily['Classification']==\"Fear\"]['total_closed_pnl'].dropna()\n",
        "greed_pnl = daily[daily['Classification']==\"Greed\"]['total_closed_pnl'].dropna()\n",
        "\n",
        "if len(fear_pnl) > 0 and len(greed_pnl) > 0:\n",
        "    tstat, pval = ttest_ind(fear_pnl, greed_pnl, equal_var=False)\n",
        "    print(\"T-test Fear vs Greed Total PnL:\")\n",
        "    print(\"t-stat:\", round(tstat,3), \"p-value:\", round(pval,4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHSLmBmR3tRq",
        "outputId": "e52be1b8-11af-4d92-bf3e-43541b803f06"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T-test Fear vs Greed Total PnL:\n",
            "t-stat: 1.654 p-value: 0.1059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Simple predictive modeling\n",
        "# -------------------------------\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "daily = daily.sort_values('date')\n",
        "daily['next_pnl_pos'] = (daily['total_closed_pnl'].shift(-1) > 0).astype(int)\n",
        "features = ['total_volume','win_rate','avg_trade_size','sent_code']\n",
        "\n",
        "df = daily.dropna(subset=features+['next_pnl_pos']).copy()\n",
        "if df.shape[0] > 20:\n",
        "    X = df[features].values\n",
        "    y = df['next_pnl_pos'].values\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "    model = LogisticRegression(max_iter=500)\n",
        "    accs=[]\n",
        "    for train_idx, test_idx in tscv.split(X_scaled):\n",
        "        model.fit(X_scaled[train_idx], y[train_idx])\n",
        "        accs.append(model.score(X_scaled[test_idx], y[test_idx]))\n",
        "    print(\"Logistic Regression mean CV accuracy:\", round(np.mean(accs),3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mgUqVFR30Qz",
        "outputId": "53be4104-8e31-4e5b-dfcf-7eb7c3e25a0e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression mean CV accuracy: 0.653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Save model-ready dataset\n",
        "# -------------------------------\n",
        "daily.to_csv(\"csv_files/daily_with_labels.csv\", index=False)"
      ],
      "metadata": {
        "id": "_wJ1YRB-33lb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Create placeholder ds_report.pdf\n",
        "# -------------------------------\n",
        "from fpdf import FPDF\n",
        "\n",
        "pdf = FPDF()\n",
        "pdf.add_page()\n",
        "pdf.set_font(\"Arial\",\"B\",16)\n",
        "pdf.cell(0,10,\"Web3 Trading Team - Data Science Report\", ln=True, align=\"C\")\n",
        "pdf.ln(10)\n",
        "\n",
        "pdf.set_font(\"Arial\",\"\",12)\n",
        "pdf.multi_cell(0,8,\"This report includes dataset description, EDA charts, insights, observations from Fear vs Greed, and modeling results.\\n\\n\")\n",
        "\n",
        "# Add images (charts saved previously)\n",
        "chart_files = [\"outputs/daily_pnl.png\", \"outputs/scatter_trade_pnl.png\"]\n",
        "for chart in chart_files:\n",
        "    pdf.add_page()\n",
        "    pdf.image(chart, x=10, y=20, w=180)  # adjust width/position as needed\n",
        "\n",
        "pdf.output(\"ds_report.pdf\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xI8cKypM37ET",
        "outputId": "d4744cb0-8180-4ce6-d3cd-b75c0a4a34be"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}